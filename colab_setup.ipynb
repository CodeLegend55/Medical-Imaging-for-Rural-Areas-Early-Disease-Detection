{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "55ad76ae",
   "metadata": {},
   "source": [
    "# Medical Imaging for Rural Areas - Google Colab Setup\n",
    "\n",
    "This notebook will help you run your medical imaging project on Google Colab with free GPU access.\n",
    "\n",
    "## Instructions:\n",
    "1. Upload your project folder to Google Drive\n",
    "2. Run this notebook in Google Colab\n",
    "3. Enable GPU runtime: Runtime → Change runtime type → Hardware accelerator → GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6da01efa",
   "metadata": {},
   "source": [
    "## Step 1: Check GPU Availability and Mount Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb6420f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if GPU is available\n",
    "import torch\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU device: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")\n",
    "else:\n",
    "    print(\"GPU not available. Please enable GPU runtime.\")\n",
    "    print(\"Go to: Runtime → Change runtime type → Hardware accelerator → GPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af650237",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Navigate to your project folder (update this path based on where you uploaded your project)\n",
    "import os\n",
    "os.chdir('/content/drive/MyDrive/Medical-Imaging-for-Rural-Areas-Early-Disease-Detection')\n",
    "\n",
    "# Verify we're in the right directory\n",
    "print(\"Current directory:\", os.getcwd())\n",
    "print(\"Files in directory:\")\n",
    "!ls -la"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0625bc2c",
   "metadata": {},
   "source": [
    "## Step 2: Install Required Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e138dd63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install -r requirements.txt\n",
    "\n",
    "# Install additional packages that might be needed\n",
    "!pip install kaggle\n",
    "!pip install pyyaml\n",
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8e5581d",
   "metadata": {},
   "source": [
    "## Step 3: Download Dataset (Optional - if not already uploaded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf265de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you need to download the dataset from Kaggle\n",
    "# First, you need to set up Kaggle API credentials\n",
    "# Upload your kaggle.json file to Colab or create it manually\n",
    "\n",
    "# Uncomment and run these lines if you need to download the dataset:\n",
    "# from google.colab import files\n",
    "# files.upload()  # Upload your kaggle.json file\n",
    "\n",
    "# !mkdir -p ~/.kaggle\n",
    "# !mv kaggle.json ~/.kaggle/\n",
    "# !chmod 600 ~/.kaggle/kaggle.json\n",
    "\n",
    "# !kaggle datasets download -d jtiptj/chest-xray-pneumoniacovid19tuberculosis\n",
    "# !unzip chest-xray-pneumoniacovid19tuberculosis.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e90bc52e",
   "metadata": {},
   "source": [
    "## Step 4: Set Up Environment and Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b220f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Add src directory to path\n",
    "sys.path.append('./src')\n",
    "\n",
    "# Import your custom modules\n",
    "from data.data_loader import load_dataset\n",
    "from models.resnet50_model import ResNet50Model\n",
    "from models.densenet121_model import DenseNet121Model\n",
    "from models.efficientnet_model import EfficientNetB0Model\n",
    "from training.train import ModelTrainer\n",
    "from training.evaluate import ModelEvaluator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d3c78a",
   "metadata": {},
   "source": [
    "## Step 5: Load and Explore Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee989fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration for Colab\n",
    "DATA_DIR = \"./chest_xray_merged\"  # Updated path for Colab\n",
    "BATCH_SIZE = 32  # Can use larger batch size in Colab with GPU\n",
    "IMAGE_SIZE = (224, 224)\n",
    "NUM_EPOCHS = 25\n",
    "LEARNING_RATE = 0.001\n",
    "NUM_CLASSES = 4\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Load dataset\n",
    "print(\"Loading dataset...\")\n",
    "train_loader, val_loader, test_loader, class_names = load_dataset(\n",
    "    DATA_DIR, \n",
    "    batch_size=BATCH_SIZE, \n",
    "    image_size=IMAGE_SIZE,\n",
    "    num_workers=2  # Can use more workers in Colab\n",
    ")\n",
    "\n",
    "print(f\"Classes: {class_names}\")\n",
    "print(f\"Training samples: {len(train_loader.dataset)}\")\n",
    "print(f\"Validation samples: {len(val_loader.dataset)}\")\n",
    "print(f\"Test samples: {len(test_loader.dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e47d99c",
   "metadata": {},
   "source": [
    "## Step 6: Visualize Sample Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b1162c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize sample images from each class\n",
    "def visualize_samples(data_loader, class_names, num_samples=8):\n",
    "    # Get a batch of training data\n",
    "    images, labels = next(iter(data_loader))\n",
    "    \n",
    "    # Create a figure\n",
    "    fig, axes = plt.subplots(2, 4, figsize=(15, 8))\n",
    "    fig.suptitle('Sample Images from Dataset', fontsize=16)\n",
    "    \n",
    "    for i in range(num_samples):\n",
    "        if i >= len(images):\n",
    "            break\n",
    "            \n",
    "        row = i // 4\n",
    "        col = i % 4\n",
    "        \n",
    "        # Denormalize image for display\n",
    "        img = images[i].permute(1, 2, 0)\n",
    "        img = img * torch.tensor([0.229, 0.224, 0.225]) + torch.tensor([0.485, 0.456, 0.406])\n",
    "        img = torch.clamp(img, 0, 1)\n",
    "        \n",
    "        axes[row, col].imshow(img)\n",
    "        axes[row, col].set_title(f'Class: {class_names[labels[i]]}')\n",
    "        axes[row, col].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Visualize samples\n",
    "visualize_samples(train_loader, class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d86ab1",
   "metadata": {},
   "source": [
    "## Step 7: Train Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b215be3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Models to train\n",
    "models_to_train = {\n",
    "    'ResNet50': ResNet50Model(num_classes=NUM_CLASSES),\n",
    "    'DenseNet121': DenseNet121Model(num_classes=NUM_CLASSES),\n",
    "    'EfficientNetB0': EfficientNetB0Model(num_classes=NUM_CLASSES)\n",
    "}\n",
    "\n",
    "results = {}\n",
    "\n",
    "# Train each model\n",
    "for model_name, model in models_to_train.items():\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"Training {model_name}\")\n",
    "    print(f\"{'='*50}\")\n",
    "    \n",
    "    # Create trainer\n",
    "    trainer = ModelTrainer(model, device, NUM_CLASSES)\n",
    "    \n",
    "    # Train model\n",
    "    trained_model = trainer.train_model(\n",
    "        train_loader, \n",
    "        val_loader, \n",
    "        num_epochs=NUM_EPOCHS,\n",
    "        learning_rate=LEARNING_RATE\n",
    "    )\n",
    "    \n",
    "    # Evaluate model\n",
    "    print(f\"\\nEvaluating {model_name}...\")\n",
    "    evaluator = ModelEvaluator(trained_model, device)\n",
    "    y_true, y_pred, accuracy = evaluator.evaluate_model(test_loader, class_names)\n",
    "    \n",
    "    # Plot training history\n",
    "    trainer.plot_training_history()\n",
    "    \n",
    "    # Save model to Google Drive\n",
    "    model_path = f\"./models/{model_name}_chest_xray_colab.pth\"\n",
    "    os.makedirs(\"./models\", exist_ok=True)\n",
    "    torch.save(trained_model.state_dict(), model_path)\n",
    "    print(f\"Model saved to {model_path}\")\n",
    "    \n",
    "    results[model_name] = {\n",
    "        'model': trained_model,\n",
    "        'trainer': trainer,\n",
    "        'accuracy': accuracy,\n",
    "        'predictions': (y_true, y_pred)\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "086704f7",
   "metadata": {},
   "source": [
    "## Step 8: Compare Results and Visualize Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb37051",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare results\n",
    "if results:\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"FINAL RESULTS COMPARISON\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    model_names = []\n",
    "    accuracies = []\n",
    "    \n",
    "    for model_name, result in results.items():\n",
    "        print(f\"{model_name}: {result['accuracy']:.4f}\")\n",
    "        model_names.append(model_name)\n",
    "        accuracies.append(result['accuracy'])\n",
    "    \n",
    "    # Find best model\n",
    "    best_model = max(results.items(), key=lambda x: x[1]['accuracy'])\n",
    "    print(f\"\\nBest model: {best_model[0]} with accuracy: {best_model[1]['accuracy']:.4f}\")\n",
    "    \n",
    "    # Plot comparison\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    bars = plt.bar(model_names, accuracies, color=['skyblue', 'lightgreen', 'lightcoral'])\n",
    "    plt.title('Model Performance Comparison', fontsize=16, fontweight='bold')\n",
    "    plt.xlabel('Models', fontsize=12)\n",
    "    plt.ylabel('Accuracy', fontsize=12)\n",
    "    plt.ylim(0, 1)\n",
    "    \n",
    "    # Add value labels on bars\n",
    "    for bar, acc in zip(bars, accuracies):\n",
    "        plt.text(bar.get_x() + bar.get_width()/2., bar.get_height() + 0.01, \n",
    "                f'{acc:.4f}', ha='center', va='bottom', fontweight='bold')\n",
    "    \n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "print(\"\\nTraining completed successfully in Google Colab!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6867289b",
   "metadata": {},
   "source": [
    "## Step 9: Download Trained Models (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e91dcc4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download trained models to your local machine\n",
    "from google.colab import files\n",
    "\n",
    "# List available model files\n",
    "model_files = [f for f in os.listdir('./models') if f.endswith('.pth')]\n",
    "print(\"Available model files:\")\n",
    "for file in model_files:\n",
    "    print(f\"- {file}\")\n",
    "\n",
    "# Uncomment to download specific model\n",
    "# files.download('./models/ResNet50_chest_xray_colab.pth')\n",
    "# files.download('./models/DenseNet121_chest_xray_colab.pth')\n",
    "# files.download('./models/EfficientNetB0_chest_xray_colab.pth')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
